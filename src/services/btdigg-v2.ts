import { meetsTitleConditions } from '@/utils/checks';
import ProxyManager from '@/utils/proxyManager';
import axios from 'axios';
import { SocksProxyAgent } from 'socks-proxy-agent';
import UserAgent from 'user-agents';
import { ScrapeSearchResult } from './mediasearch';

const BTDIG = 'http://btdigggink2pdqzqrik3blmqemsbntpzwxottujilcdjfz56jumzfsyd.onion';
const MAX_RESULTS_PER_PAGE = 10;
const BAD_RESULT_THRESHOLD = 20;

export const createAxiosInstance = (agent: SocksProxyAgent) => {
	return axios.create({
		httpAgent: BTDIG.startsWith('http://') ? agent : undefined,
		headers: {
			accept: 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
			'accept-language': 'en-US,en;q=0.5',
			'accept-encoding': 'gzip, deflate, br',
			referer: `${BTDIG}/`,
			connection: 'keep-alive',
			'sec-fetch-dest': 'document',
			'sec-fetch-mode': 'navigate',
			'sec-fetch-site': 'same-origin',
			'sec-fetch-user': '?1',
			'upgrade-insecure-requests': '1',
			'user-agent': new UserAgent().toString(),
		},
		timeout: parseInt(process.env.REQUEST_TIMEOUT || '3000', 10),
	});
};

function convertToMB(fileSizeStr: string) {
	let fileSize = parseFloat(fileSizeStr); // extracts the numeric part
	if (fileSizeStr.includes('GB')) {
		fileSize *= 1024; // if GB, convert to MB
	}
	return Math.round(fileSize); // returns the rounded integer value
}

function isFoundDateRecent(foundString: string, date: string): boolean {
	const regex = /found\s(\d+)\s(years?|months?|weeks?|days?|hours?|minutes?|seconds?)\sago/;
	const match = foundString.match(regex);

	if (!match) {
		throw new Error('Invalid found string');
	}

	const value = parseInt(match[1]);
	const unit = match[2];

	// set found date to last possible moment of the unit
	const foundDate = new Date();
	switch (unit) {
		case 'years':
		case 'year':
			foundDate.setFullYear(foundDate.getFullYear() - value);
			break;
		case 'months':
		case 'month':
			foundDate.setMonth(foundDate.getMonth() - value);
			break;
		case 'weeks':
		case 'week':
			foundDate.setDate(foundDate.getDate() - 7 * value);
			break;
		case 'days':
		case 'day':
			foundDate.setDate(foundDate.getDate() - value);
			break;
		case 'hours':
		case 'hour':
			return true;
		case 'minutes':
		case 'minute':
			return true;
		case 'seconds':
		case 'second':
			return true;
		default:
			throw new Error('Invalid unit');
	}

	const airDate = new Date(date);

	// Return true if the found date is more recent or equal
	return foundDate >= airDate;
}

const createSearchUrl = (finalQuery: string, pg: number) =>
	`${BTDIG}/search?order=0&q=${encodeURIComponent(finalQuery)}&p=${pg - 1}`;

type ProcessPageResult = {
	results: ScrapeSearchResult[];
	badCount: number;
	numResults: number;
};

const processPage = async (
	finalQuery: string,
	targetTitle: string,
	years: string[],
	airDate: string,
	pageNum: number
): Promise<ProcessPageResult> => {
	const MAX_RETRIES = 5; // maximum number of retries

	let results: ScrapeSearchResult[] = [];
	let badCount = 0;
	let retries = 0; // current number of retries
	let responseData = '';
	let numResults = 0;
	const searchUrl = createSearchUrl(finalQuery, pageNum);
	let proxy = new ProxyManager();
	while (true) {
		try {
			const torProxy = proxy.getWorkingProxy();
			const client = createAxiosInstance(torProxy);
			const response = await client.get(searchUrl);
			responseData = response.data;
			const numResultsStr = responseData.match(/(\d+) results found/) || [];
			numResults = parseInt(numResultsStr[1], 10);
			retries = 0;
			break;
		} catch (error: any) {
			if (error.message.includes('status code 404') && pageNum === 1) {
				console.error('404 error, aborting search');
				return { results, badCount: MAX_RESULTS_PER_PAGE, numResults };
			} else if (
				error.message.includes('status code 429') ||
				error.message.includes('"socket" was not created')
			) {
				proxy.rerollProxy();
				retries++;
			} else if (error.message.includes('timeout of')) {
				retries++;
			} else {
				console.log('request error:', error.message, searchUrl);
				retries++;
				if (retries >= MAX_RETRIES) {
					console.error(`Max retries reached (${MAX_RETRIES}), aborting search`);
					return { results, badCount: MAX_RESULTS_PER_PAGE, numResults };
				}
			}
			await new Promise((resolve) => setTimeout(resolve, 10000 * retries));
		}
	}
	const fileSizes = Array.from(
		responseData.matchAll(/class=\"torrent_size\"[^>]*>(\d+(?:\.\d+)?)(?:[^A-Z<]+)?([A-Z]+)?/g)
	);
	const namesAndHashes = Array.from(
		responseData.matchAll(/magnet:\?xt=urn:btih:([a-z\d]{40})&amp;dn=([^&]+)&/g)
	);
	const ages = Array.from(responseData.matchAll(/class=\"torrent_age\"[^>]*>([^<]+)/g));

	if (fileSizes.length !== namesAndHashes.length || fileSizes.length !== ages.length) {
		console.warn('Mismatch in file sizes and names');
		return { results, badCount: MAX_RESULTS_PER_PAGE, numResults };
	}

	for (let resIndex = 0; resIndex < fileSizes.length; resIndex++) {
		const title = decodeURIComponent(namesAndHashes[resIndex][2].replaceAll('+', ' '));
		const fileSizeStr = `${fileSizes[resIndex][1]} ${fileSizes[resIndex][2] || 'B'}`;

		if (!fileSizeStr.includes('GB') && !fileSizeStr.includes('MB')) {
			badCount++;
			continue;
		}
		const fileSize = convertToMB(fileSizeStr);

		if (!isFoundDateRecent(ages[resIndex][1], airDate)) {
			badCount++;
			continue;
		}

		if (!meetsTitleConditions(targetTitle, years, title)) {
			badCount++;
			continue;
		}

		const hash = namesAndHashes[resIndex][1];

		let resultObj = {
			title,
			fileSize,
			hash,
		};

		results.push(resultObj);
	}

	return { results, badCount, numResults };
};

function calculateMaxPages(
	numResults: number,
	resultsPerPage: number = 10,
	maxPageNum: number = 100
): number {
	let totalPages = Math.ceil(numResults / resultsPerPage);
	return totalPages > maxPageNum ? maxPageNum : totalPages;
}

async function processInBatches(
	title: string,
	promises: (() => Promise<ProcessPageResult>)[],
	batchSize: number
): Promise<ScrapeSearchResult[]> {
	let searchResultsArr: ScrapeSearchResult[] = [];
	let i = 0;
	let lastPrintedIndex = 0;
	while (i < promises.length) {
		let percentageIncrease = ((i - lastPrintedIndex) / promises.length) * 100;
		if (percentageIncrease >= 20) {
			console.log(`🌃 Btdigg batch ${i}/${promises.length}:${title}`);
			lastPrintedIndex = i;
		}
		let totalBadCount = 0;
		const promisesResults = await Promise.all(
			promises.slice(i, i + batchSize).map(async (e) => await e())
		);
		const results = promisesResults.reduce(
			(acc: ScrapeSearchResult[], val: ProcessPageResult) => acc.concat(val.results),
			[]
		);
		totalBadCount = promisesResults.reduce(
			(acc: number, val: ProcessPageResult) => (acc += val.badCount),
			totalBadCount
		);
		searchResultsArr.push(...results);
		i += batchSize;
		if (totalBadCount >= BAD_RESULT_THRESHOLD) {
			break;
		}
	}
	console.log(`🌃 Btdigg done! ${title}`);
	return searchResultsArr;
}

export async function scrapeBtdigg(
	finalQuery: string,
	targetTitle: string,
	years: string[],
	airDate: string
): Promise<ScrapeSearchResult[]> {
	let searchResultsArr: ScrapeSearchResult[] = [];
	while (true) {
		console.log(`🔍 Searching Btdigg: ${finalQuery}`);
		try {
			let pageNum = 1;
			const { results, numResults } = await processPage(
				finalQuery,
				targetTitle,
				years,
				airDate,
				pageNum++
			);
			console.log(`🌃 Btdigg search returned ${numResults} for ${finalQuery}`);
			searchResultsArr.push(...results);
			const maxPages = calculateMaxPages(numResults);
			let promises: (() => Promise<ProcessPageResult>)[] = [];
			for (let pageNum = 1; pageNum <= maxPages; pageNum++) {
				const processPageBound: () => Promise<any> = async () => {
					return processPage(finalQuery, targetTitle, years, airDate, pageNum);
				};
				promises.push(processPageBound);
			}
			searchResultsArr.push(...(await processInBatches(finalQuery, promises, 5)));
		} catch (error) {
			console.error('scrapeBtdigg page processing error', error);
			await new Promise((resolve) => setTimeout(resolve, 5000));
		}
		// mkv
		try {
			let pageNum = 1;
			const { results, numResults } = await processPage(
				`${finalQuery} .mkv`,
				targetTitle,
				years,
				airDate,
				pageNum++
			);
			searchResultsArr.push(...results);
			const maxPages = calculateMaxPages(numResults);
			let promises: (() => Promise<ProcessPageResult>)[] = [];
			while (pageNum <= maxPages) {
				promises.push(
					((pageNum) => async () => {
						return await processPage(
							`${finalQuery} .mkv`,
							targetTitle,
							years,
							airDate,
							pageNum
						);
					})(pageNum)
				);
				pageNum++;
			}
			searchResultsArr.push(...(await processInBatches(`${finalQuery} .mkv`, promises, 5)));
		} catch (error) {
			console.error('scrapeBtdigg mkv page processing error', error);
			await new Promise((resolve) => setTimeout(resolve, 5000));
		}
		// mp4
		try {
			let pageNum = 1;
			const { results, numResults } = await processPage(
				`${finalQuery} .mp4`,
				targetTitle,
				years,
				airDate,
				pageNum++
			);
			searchResultsArr.push(...results);
			const maxPages = calculateMaxPages(numResults);
			let promises: (() => Promise<ProcessPageResult>)[] = [];
			while (pageNum <= maxPages) {
				promises.push(
					((pageNum) => async () => {
						return await processPage(
							`${finalQuery} .mp4`,
							targetTitle,
							years,
							airDate,
							pageNum
						);
					})(pageNum)
				);
				pageNum++;
			}
			searchResultsArr.push(...(await processInBatches(`${finalQuery} .mp4`, promises, 5)));
		} catch (error) {
			console.error('scrapeBtdigg mp4 page processing error', error);
			await new Promise((resolve) => setTimeout(resolve, 5000));
		}
		return searchResultsArr;
	}
}
